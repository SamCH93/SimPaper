\documentclass[a4paper, 11pt]{article}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{graphics}
\usepackage[dvipsnames]{xcolor}
\usepackage{amsmath, amssymb}
\usepackage{textcomp}
\usepackage[sc]{mathpazo}
\usepackage{times}
\usepackage{doi} % automatic doi-links
\usepackage[round]{natbib} % bibliography
\usepackage{multirow} % multi rows and columns for tables
\usepackage{longtable} % tables that span several pages
\usepackage{booktabs} % nicer tables
\usepackage[toc, page]{appendix} % better appendices
\usepackage{nameref} % reference appendices with names
\usepackage{todonotes} 
\usepackage{pdflscape} 

\input{defs}

%% margins
%% ----------------------------------------------------------------------------
\usepackage{geometry}
 \geometry{
 a4paper,
 total={170mm,257mm},
 left=25mm,
 right=25mm,
 top=20mm,
 bottom=20mm,
 }

%% title, authors, affiliations, mail
%% ----------------------------------------------------------------------------
\newcommand\longtitle{Pitfalls and Potentials in Simulation Studies}
\newcommand\shorttitle{\longtitle}
\newcommand\subtitle{Report of preregistered simulations}
\newcommand\longauthors{Samuel Pawel, Lucas Kook, Kelly Reeve}
\newcommand\shortauthors{\longauthors} % if longauthors too long, change here
\newcommand\affiliation{
  Epidemiology, Biostatistics and Prevention Institute (EBPI) \\
  Center for Reproducible Science (CRS) \\
  University of Zurich
}
\newcommand\mail{}
\title{
  \vspace{-2em}
  \textbf{\longtitle} \\
  \subtitle
}
\author{
  \textbf{\longauthors}
}
\date{\today} % don't forget to hard-code date when submitting to arXiv!

%% hyperref options
%% ----------------------------------------------------------------------------
\usepackage{hyperref}  
\hypersetup{
  bookmarksopen=true, 
  breaklinks=true,
  pdftitle={\shorttitle}, 
  pdfauthor={\shortauthors},
  pdfsubject={},
  pdfkeywords={},
  colorlinks=true,
  linkcolor=RoyalPurple,
  anchorcolor=black,
  citecolor=MidnightBlue,
  urlcolor=BrickRed,
}

%% Headers and footers
%% ----------------------------------------------------------------------------
\usepackage{fancyhdr}
\pagestyle{fancy}
\lhead{\shorttitle}
\rhead{\shortauthors}

\begin{document}
\maketitle



% knitr options
% =============================================================================
<< "main-setup", include = FALSE >>=
library(knitr)
opts_chunk$set(fig.height = 4,
               echo = FALSE,
               warning = FALSE,
               message = FALSE,
               cache = FALSE, 
               eval = TRUE)
@

In this document we describe the outcomes of the preregistered simulations.
$\dots$

Taken together, the performance of \ainet{} was virtually identical to elastic
net regression. The addition of the adaptive penalization weights does not seem
to make a difference for the data generating mechanism considered. Moreover,
since the data were generated under a process equivalent to a logistic
regression model, it is of no surprise that for reasonably sample sizes, this
model also performed the best with respect to various metrics (most notably the
the Brier score). The only exception are conditions with very small sample size
and low number of events per variable. The random forest was outperformed by
\ainet{} in most simulation condtions, with exception of very small sample size
and prevalence simulation conditions, as well as when a high correlation between
covariates was present. Finally, the performance of the adpative elastic net was
generally worse compared to \ainet{}.

\section{Brier score (main estimand)}
Figure~\ref{fig:tiebrier} shows the differences in mean Brier score between
\ainet{} and the other methods stratified by simulation conditions.

% elastic net
We see that there is hardly any difference between \ainet{} and elastic net (EN)
across all simulation conditions meaning that predictive performance of both
methods seems to be very similar in the investigated scenarios.

% random forest
The random forest (RF) shows better predictive performance than \ainet{} in
conditions with very low sample size ($n = 100$) and prevalence
($\mbox{prev} = 0.01$). For increasing sample size and prevalence, the
performance of \ainet{} seems to become more similar or improve over RF when the
correlation of the covariates is not too large ($\rho \leq 0.6$) especially for
low events per variable ($\mbox{EPV} \leq 1$). For highly correlated covariates
($\rho = 0.95$), the performance of \ainet{} is similar or worse across most
simulation conditions.

Logistic regression (GLM) showed better predictive performance compared to
\ainet{} in most simulation conditions. An exception are the conditions with
small sample size ($n = 100$), medium to large prevalence
($\mbox{prev} \geq 0.05$) and low events per variable ($\mbox{EPV} \leq 1$),
where \ainet{} performed better than GLM.

The adaptive elastic net (AEN) method performed worse than \ainet{} in almost
all simulation conditions. Only in conditions with very large sample size
($n = 5000$), very small prevalence ($\mbox{prev} = 0.01$), and high events per
variable ($\mbox{EPV} = 20$), AEN showed predictive performance on par with
\ainet{}.

\section{Scaled Brier score (secondary estimand)}
Figure~\ref{fig:tiesbrier} shows the differences in scaled Brier score between
\ainet{} and the other methods stratified by simulation conditions. The scaled
Brier score is useful to compare the actual values of Brier scores across
conditions with different prevalence, but not so much to compare Brier scores of
different methods within a simulation condition with fixed prevalence. We see
that for most conditions the plots look like a flipped version of the unscaled
Brier scores from Figure~\ref{fig:tiebrier}. Therefore, conclusions are mostly
the same. For very small sample sizes coupled with low prevalence and low events
per variable (the topleft plots), the scaled Brier score indicates superiority
of \ainet{} over RF and GLM, which is opposite the conclusion based on the raw
Brier score. We advise to interpret these conditions cautiously since the
prevalence prediction which is used for scaling is based on the much larger test
data set.

\section{Log score (secondary estimand)}
Figure~\ref{fig:tienll} shows the differences in log score between \ainet{} and
the other methods stratified by simulation conditions. We see that in certain
conditions, the error bars of certain methods are much larger. This is due to
the log score's sensitivity to extreme predictions, which often happen under the
RF (and sometimes under the GLM). Despite the larger variability of the log
score, conclusion regarding the comparison between \ainet{} and the other
methods are largely the same as under the Brier score.


\section{Area under the curve (secondary estimand)}
Figure~\ref{fig:tienll} shows the differences in area under the curve (AUC)
between \ainet{} and the other methods stratified by simulation conditions.

As with the other estimands, \ainet{} delivers virtually identical performance
as EN regression across all simulation conditions.

\ainet{} seems to outperform RF across most simulation conditions, with the
exception of a conditions with low sample size ($n = 100$), medium prevalence
($\mbox{prev} = 0.05$), and low events per variable ($\mbox{EPV} \leq 1$).

GLM, typically outperforms \ainet{} conditions with small to medium sample size
($n \leq 500$), and also in conditions with larger sample size when the
events per variable is normal to high ($\mbox{EPV} \geq 10$) and the prevalence
is small ($\mbox{prev}  = 0.01$).

Finally, the AEN is worse with respect to AUC than \ainet{} across all
simulation conditions.


\section{Calibration slope (secondary estimand)}
Figure~\ref{fig:cslope} shows boxplots of the calibration slope stratified by
simulation condition and method.

\todo{Add information on non-convergent calibration slope}
We caution to interpret the random forest (RF) calibration slopes because
this method often resulted in predicted probabilities of zero or one, so that
a calibration slope could not be fitted.

We see that logistic regression (GLM) shows on average optimal calibration in
most simulation condition. In cases where it is off the optimal value of one,
its calibration slopes are usually too small indicating overoptimistic
predictions. In general, worse calibration slopes are obtained for lower event
per variable (EPV).



\section{Calibration in the large (secondary estimand)}



\begin{landscape}
\begin{figure}[!ht]
\center
\includegraphics[width=0.9\linewidth]{../results_anova/tie-fighter_brier.pdf}
\caption{Tie-fighter plot for the difference in Brier score between any method
  on the $y$-axis and \ainet{}. The 95\% confidence intervals are adjusted per
  simulation condition using the single-step method. Lower values indicate
  better performance of \ainet{}. } \label{fig:tiebrier}
\end{figure}
\end{landscape}

\begin{landscape}
\begin{figure}[!ht]
\center
\includegraphics[width=0.9\linewidth]{../results_anova/tie-fighter_scaledBrier.pdf}
\caption{Tie-fighter plot for the difference in scaled Brier score between any
  method on the $y$-axis and \ainet{}. The 95\% confidence intervals are adjusted
  per simulation condition using the single-step method. Larger
  values indicate better performance of \ainet{}. } \label{fig:tiesbrier}
\end{figure}
\end{landscape}

\begin{landscape}
\begin{figure}[!ht]
\center
\includegraphics[width=0.9\linewidth]{../results_anova/tie-fighter_nll.pdf}
\caption{Tie-fighter plot for the difference in log score between any method on
  the $y$-axis and \ainet{}. The 95\% confidence intervals are adjusted per
  simulation condition using the single-step method. Lower values indicate
  better performance of \ainet{}. } \label{fig:tienll}
\end{figure}
\end{landscape}

\begin{landscape}
\begin{figure}[!ht]
\center
\includegraphics[width=0.9\linewidth]{../figures/calibration-cslope.pdf}
\caption{Boxplots of calibration slopes stratified by method and simulation
  conditions. Mean calibration slope is indicated by a cross. A value of one
  indicates optimal calibration.} \label{fig:cslope}
\end{figure}
\end{landscape}

\begin{landscape}
\begin{figure}[!ht]
\center
\includegraphics[width=0.9\linewidth]{../figures/calibration-clarge.pdf}
\caption{Boxplots of calibration in the large stratified by method and
  simulation conditions. Mean calibration in the large is indicated by a cross.
  A value of zero indicates optimal calibration in the
  large.} \label{fig:clarge}
\end{figure}
\end{landscape}

\end{document}
